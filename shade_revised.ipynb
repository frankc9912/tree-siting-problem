{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0bb8b0f",
   "metadata": {},
   "source": [
    "## Shade Computation\n",
    "\n",
    "In this notebook, we will use GPU to compute the shade for each potetial tree site. We use the LiDAR-derived digital Surface Model (DSM) to compute the shade. By creating a patch for each potential tree site, we can compute:\n",
    "\n",
    "- S_original: The original shade of the patch using the DSM.\n",
    "- S_planted: The shade of the patch after planting a tree using `apply_tree_to_dsm()`.\n",
    "- S_unique: The unique shade of the patch after planting a tree, which is the difference between S_planted and S_original.\n",
    "- S_unique_on_edge: The unique shade of the patch on the edges of the road network graph, which is the vectorized unique shade that intersects with the road network edge gdf.\n",
    "\n",
    "By moving two patches using their coordinates, we can compute the overlap between two potential tree sites:\n",
    "\n",
    "- S_overlap: The overlap shade between two patches, which is the intersection of their unique shades.\n",
    "- S_overlap_on_edge: The overlap shade on the edges of the road network graph, which is the vectorized overlap shade that intersects with the road network edge gdf.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcb6359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 device(s) found.\n",
      "Device #0: NVIDIA GeForce RTX 3070\n",
      "<module 'pycuda.driver' from '/home/ubuntu24/miniforge3/envs/spatial/lib/python3.12/site-packages/pycuda/driver.py'>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from tqdm import tqdm, trange\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "from rasterio.merge import merge\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from rasterio.windows import Window\n",
    "from shapely.geometry import shape, box\n",
    "from shapely.ops import unary_union\n",
    "import rasterio.features\n",
    "import gc\n",
    "  \n",
    "\n",
    "print(\"%d device(s) found.\" % cuda.Device.count())\n",
    "for ordinal in range(cuda.Device.count()):\n",
    "    dev = cuda.Device(ordinal)\n",
    "    print (\"Device #%d: %s\" % (ordinal, dev.name()))\n",
    "print (cuda)\n",
    "\n",
    "# -------------------- PARAMETERS --------------------\n",
    "# TILE_DIR = \"/mnt/e/Capstone/data/tiles_output/test\"\n",
    "TILE_DIR = \"/mnt/e/Capstone/data/tiles_output/dsm\"\n",
    "SITES_FP = \"/mnt/e/Capstone/data/final/sites_tree.geojson\"\n",
    "FINAL_GEOJSON = \"data/final/final_sites.geojson\"\n",
    "STACK_OUT_DIR = \"data/tiles_output/stacks\"\n",
    "\n",
    "os.makedirs(\"data/final/overlap_tile\", exist_ok=True)\n",
    "os.makedirs(\"data/final/sites_tile\", exist_ok=True)\n",
    "os.makedirs(\"data/final/shade_on_edge_tile\", exist_ok=True)\n",
    "os.makedirs(\"data/final/overlap_shade_on_edge_tile\", exist_ok=True)\n",
    "\n",
    "PATCH_SIZE = 512\n",
    "HALF_PATCH = PATCH_SIZE // 2\n",
    "PIXEL_SIZE = 1.0  # in feet\n",
    "# 2 pm, July 1st\n",
    "AZIMUTH = 243.9  # degrees\n",
    "ELEVATION = 60.38  # degrees\n",
    "EDGE_HEIGHT_FRACTION = 0.3  # 30% height at canopy edge\n",
    "\n",
    "sites_gdf = gpd.read_file(SITES_FP)\n",
    "\n",
    "# Add columns for your shade stats\n",
    "for col in [\"shade_area\",\"overlap_with_existing\",\"unique_shade_area\",\"overlap_with_new_trees\"]:\n",
    "    sites_gdf[col] = 0.0\n",
    "\n",
    "with open(\"/mnt/e/Capstone/data/sites/test/G_ideal.pkl\", \"rb\") as f:\n",
    "    G_ideal = pickle.load(f)\n",
    "\n",
    "# ----- Nodes DataFrame -----\n",
    "nodes = [\n",
    "    {\"node\": n, **attrs}\n",
    "    for n, attrs in G_ideal.nodes(data=True)\n",
    "]\n",
    "nodes_df = pd.DataFrame(nodes)\n",
    "origins = nodes_df.loc[nodes_df[\"visit_count\"] != 0].reset_index(drop=True)\n",
    "\n",
    "edges = [\n",
    "    {\"origin_node\": u, \"dest_node\": v, **data}\n",
    "    for u, v, data in G_ideal.edges(data=True)\n",
    "]\n",
    "edges_df = pd.DataFrame(edges)\n",
    "edges_gdf = gpd.GeoDataFrame(edges_df, geometry=\"geometry\", crs=sites_gdf.crs)\n",
    "\n",
    "# CUDA Kernel\n",
    "CUDA_KERNEL = \"\"\"\n",
    "#define PI 3.1415926\n",
    "\n",
    "__global__ void calculate_shadow(float *dsm, bool *shadow, int width, int height, float cell_size, float sun_azimuth, float sun_elevation) {\n",
    "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    // Check if the thread is within the bounds of the image\n",
    "    if (x >= width || y >= height)\n",
    "        return;\n",
    "\n",
    "    int idx = y * width + x;\n",
    "\n",
    "    // Convert sun azimuth and elevation to radians\n",
    "    float azimuth_rad = sun_azimuth * 3.14159 / 180.0;\n",
    "    float elevation_rad = sun_elevation * 3.14159 / 180.0;\n",
    "\n",
    "    // Direction of the shadow ray based on sun azimuth\n",
    "    float dx = sin(azimuth_rad);\n",
    "    float dy = -cos(azimuth_rad);\n",
    "    float dz = tan(elevation_rad);\n",
    "\n",
    "    // Initial height at the current pixel\n",
    "    float initial_height = dsm[idx];\n",
    "    bool in_shadow = false;\n",
    "\n",
    "    // Trace the shadow ray\n",
    "    for (float t = cell_size; t < 2000.0f; t += cell_size) { // Limit tracing distance\n",
    "        int x_offset = x + int(dx * t / cell_size);\n",
    "        int y_offset = y + int(dy * t / cell_size);\n",
    "\n",
    "        if (x_offset < 0 || x_offset >= width || y_offset < 0 || y_offset >= height)\n",
    "            break;  // Out of bounds\n",
    "\n",
    "        int offset_idx = y_offset * width + x_offset;\n",
    "\n",
    "        // Calculate height along the ray\n",
    "        float height_along_ray = initial_height + dz * t;\n",
    "\n",
    "        // Check if there is a higher point along the path\n",
    "        if (dsm[offset_idx] > height_along_ray) {\n",
    "            in_shadow = true;\n",
    "            break;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Store shadow result: 1 for shadow, 0 for no shadow\n",
    "    shadow[idx] = in_shadow;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "mod = SourceModule(CUDA_KERNEL)\n",
    "shadow_kernel = mod.get_function(\"calculate_shadow\")\n",
    "\n",
    "# -------------------- FUNCTIONS --------------------\n",
    "# def apply_tree_to_dsm(dsm_patch, cx, cy, height, canopy_radius):\n",
    "#     Y, X = np.ogrid[:dsm_patch.shape[0], :dsm_patch.shape[1]]\n",
    "#     dist = np.sqrt((X - cx)**2 + (Y - cy)**2)\n",
    "#     mask = dist <= canopy_radius\n",
    "#     # dome profile\n",
    "#     profile = height * np.sqrt(1 - (dist[mask] / canopy_radius)**2)\n",
    "#     patched = dsm_patch.copy()\n",
    "#     patched[mask] += profile\n",
    "#     return patched\n",
    "def apply_tree_to_dsm(dsm_patch, cx, cy, height, canopy_radius):\n",
    "    Y, X = np.ogrid[:dsm_patch.shape[0], :dsm_patch.shape[1]]\n",
    "    dist = np.sqrt((X - cx)**2 + (Y - cy)**2)\n",
    "    mask = dist <= canopy_radius\n",
    "\n",
    "    # 计算新树冠球的高度profile\n",
    "    profile = height * np.sqrt(1 - (dist[mask] / canopy_radius)**2)\n",
    "    patched = dsm_patch.copy()\n",
    "\n",
    "    # 树冠高度分布加到基底（种树点下方DSM的高度 a）\n",
    "    base_height = dsm_patch[int(cy), int(cx)]\n",
    "    tree_heights = base_height + profile  # 新树的实际高程\n",
    "\n",
    "    # 替换DSM，取最大值\n",
    "    patched[mask] = np.maximum(dsm_patch[mask], tree_heights)\n",
    "    return patched\n",
    "\n",
    "\n",
    "def compute_shadow(dsm_patch, azimuth, elevation):\n",
    "    h, w = dsm_patch.shape\n",
    "    flat_dsm = dsm_patch.astype(np.float32).ravel()\n",
    "    shadow_result = np.zeros_like(flat_dsm, dtype=np.bool_)\n",
    "    dsm_gpu = cuda.mem_alloc(flat_dsm.nbytes)\n",
    "    shadow_gpu = cuda.mem_alloc(shadow_result.nbytes)\n",
    "\n",
    "    cuda.memcpy_htod(dsm_gpu, flat_dsm)\n",
    "    cuda.memcpy_htod(shadow_gpu, shadow_result)\n",
    "\n",
    "    block = (16, 16, 1)\n",
    "    grid = ((w + 15) // 16, (h + 15) // 16)\n",
    "\n",
    "    shadow_kernel(dsm_gpu, shadow_gpu,\n",
    "        np.int32(w), np.int32(h),\n",
    "        np.float32(PIXEL_SIZE),\n",
    "        np.float32(azimuth), np.float32(elevation),\n",
    "        block=block, grid=grid)\n",
    "\n",
    "    cuda.memcpy_dtoh(shadow_result, shadow_gpu)\n",
    "    return shadow_result.reshape((h, w))\n",
    "\n",
    "def compute_unique_shade_area(unique_shade_mask, transform, edges_gdf):\n",
    "    \"\"\"\n",
    "    Vectorize unique shade mask and compute intersection with edges\n",
    "    Returns list of (edge_id, intersection_length) tuples\n",
    "    \"\"\"\n",
    "    if not unique_shade_mask.any():\n",
    "        return []\n",
    "    \n",
    "    shapes = rasterio.features.shapes(\n",
    "        unique_shade_mask.astype(\"uint8\"),\n",
    "        mask=unique_shade_mask,\n",
    "        transform=transform\n",
    "    )\n",
    "    polys = [shape(geom) for geom, val in shapes if val == 1]\n",
    "    if not polys:\n",
    "        return []\n",
    "    \n",
    "    shadow_union = unary_union(polys)\n",
    "    \n",
    "    # Get bounding box for spatial filtering\n",
    "    minx, miny, maxx, maxy = shadow_union.bounds\n",
    "    edges_in_patch = edges_gdf.cx[minx:maxx, miny:maxy]\n",
    "    \n",
    "    edge_intersections = []\n",
    "    for eidx, erow in edges_in_patch.iterrows():\n",
    "        inter = erow.geometry.intersection(shadow_union)\n",
    "        if not inter.is_empty:\n",
    "            edge_intersections.append((eidx, inter.length))\n",
    "    \n",
    "    return edge_intersections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ae109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sort tiles\n",
    "tile_files = sorted(f for f in os.listdir(TILE_DIR) if f.endswith(\".tif\"))\n",
    "\n",
    "for tile_file in tqdm(tile_files, desc=\"Processing tiles\"):\n",
    "    tile_id = os.path.splitext(tile_file)[0].split(\"_\")[-1]\n",
    "    tile_fp = os.path.join(TILE_DIR, tile_file)\n",
    "\n",
    "    # Collectors for this tile\n",
    "    shade_on_edge_records = []\n",
    "    overlap_records = []\n",
    "    overlap_shade_on_edge_records = []\n",
    "\n",
    "    with rasterio.open(tile_fp) as dsm_ds:\n",
    "        dsm = dsm_ds.read(1, out_dtype=\"float32\")\n",
    "        transform = dsm_ds.transform\n",
    "        height, width = dsm.shape\n",
    "\n",
    "        # STEP 1: Calculate baseline shadow mask for the entire tile (once)\n",
    "        print(f\"Computing baseline shadow for tile {tile_id}\")\n",
    "        baseline_shadow_tile = compute_shadow(dsm, AZIMUTH, ELEVATION)\n",
    "\n",
    "        # Define tile bounds for site selection\n",
    "        full_bounds = rasterio.windows.bounds(\n",
    "            Window(500, 500, 10000, 10000),\n",
    "            transform\n",
    "        )\n",
    "        tile_geom = box(*full_bounds)\n",
    "\n",
    "        # Select sites in this tile\n",
    "        tile_sites = sites_gdf[sites_gdf.intersects(tile_geom)].copy()\n",
    "        if tile_sites.empty:\n",
    "            continue\n",
    "\n",
    "        # Storage for patch data\n",
    "        site_data = {}  # {site_id: {'unique_mask': array, 'px': int, 'py': int, 'patch_transform': transform}}\n",
    "\n",
    "        # STEP 2-4: Process each tree site\n",
    "        for i in trange(len(tile_sites), desc=f\"Tile {tile_id} - Processing Trees\", leave=False):\n",
    "            site = tile_sites.iloc[i]\n",
    "            site_id = site.name\n",
    "            x, y = site.geometry.x, site.geometry.y\n",
    "            px, py = map(int, ~transform * (x, y))\n",
    "\n",
    "            # Check if patch is within bounds\n",
    "            if px < HALF_PATCH or py < HALF_PATCH or px > width - HALF_PATCH or py > height - HALF_PATCH:\n",
    "                continue\n",
    "\n",
    "            # STEP 2: Create 512x512 patch and extract baseline shade\n",
    "            dsm_patch = dsm[py - HALF_PATCH: py + HALF_PATCH,\n",
    "                            px - HALF_PATCH: px + HALF_PATCH]\n",
    "            \n",
    "            baseline_shadow_patch = baseline_shadow_tile[\n",
    "                py - HALF_PATCH: py + HALF_PATCH,\n",
    "                px - HALF_PATCH: px + HALF_PATCH\n",
    "            ]\n",
    "\n",
    "            # STEP 3: Simulate new tree and calculate unique shade\n",
    "            tree_dsm = apply_tree_to_dsm(\n",
    "                dsm_patch.copy(),\n",
    "                HALF_PATCH, HALF_PATCH,\n",
    "                site[\"height\"], site[\"canopy_radius\"]\n",
    "            )\n",
    "            \n",
    "            tree_shadow = compute_shadow(tree_dsm, AZIMUTH, ELEVATION)\n",
    "            \n",
    "            # Unique shade = new shade - baseline shade\n",
    "            unique_shade_mask = tree_shadow & ~baseline_shadow_patch\n",
    "\n",
    "            # Store patch data for overlap calculations\n",
    "            window = Window(px - HALF_PATCH, py - HALF_PATCH, PATCH_SIZE, PATCH_SIZE)\n",
    "            patch_transform = rasterio.windows.transform(window, transform)\n",
    "            \n",
    "            site_data[site_id] = {\n",
    "                'unique_mask': unique_shade_mask,\n",
    "                'px': px,\n",
    "                'py': py,\n",
    "                'patch_transform': patch_transform\n",
    "            }\n",
    "\n",
    "            # STEP 4: Calculate shade on edges for this tree\n",
    "            edge_intersections = compute_unique_shade_area(unique_shade_mask, patch_transform, edges_gdf)\n",
    "            for edge_id, length in edge_intersections:\n",
    "                shade_on_edge_records.append((site_id, edge_id, length))\n",
    "\n",
    "            # Update site statistics\n",
    "            unique_area = unique_shade_mask.sum() * PIXEL_SIZE**2\n",
    "            overlap_old = (tree_shadow & baseline_shadow_patch).sum() * PIXEL_SIZE**2\n",
    "            sites_gdf.at[site_id, \"unique_shade_area\"] = unique_area\n",
    "            sites_gdf.at[site_id, \"overlap_with_existing\"] = overlap_old\n",
    "            sites_gdf.at[site_id, \"shade_area\"] = unique_area + overlap_old\n",
    "\n",
    "        # STEP 5-7: Calculate pairwise overlaps\n",
    "        site_ids = list(site_data.keys())\n",
    "        for i in trange(len(site_ids), desc=f\"Tile {tile_id} - Pairwise Overlaps\", leave=False):\n",
    "            site_i = site_ids[i]\n",
    "            data_i = site_data[site_i]\n",
    "            \n",
    "            for j in range(i + 1, len(site_ids)):\n",
    "                site_j = site_ids[j]\n",
    "                data_j = site_data[site_j]\n",
    "\n",
    "                # STEP 5: Check if patches can overlap\n",
    "                dx = data_j['px'] - data_i['px']\n",
    "                dy = data_j['py'] - data_i['py']\n",
    "                \n",
    "                if abs(dx) >= PATCH_SIZE or abs(dy) >= PATCH_SIZE:\n",
    "                    continue  # Patches too far apart\n",
    "\n",
    "                # Calculate overlap region in each patch's coordinate system\n",
    "                if dx >= 0:\n",
    "                    xi0, xi1 = dx, PATCH_SIZE\n",
    "                    xj0, xj1 = 0, PATCH_SIZE - dx\n",
    "                else:\n",
    "                    xi0, xi1 = 0, PATCH_SIZE + dx\n",
    "                    xj0, xj1 = -dx, PATCH_SIZE\n",
    "\n",
    "                if dy >= 0:\n",
    "                    yi0, yi1 = dy, PATCH_SIZE\n",
    "                    yj0, yj1 = 0, PATCH_SIZE - dy\n",
    "                else:\n",
    "                    yi0, yi1 = 0, PATCH_SIZE + dy\n",
    "                    yj0, yj1 = -dy, PATCH_SIZE\n",
    "\n",
    "                \n",
    "                if xi1 <= xi0 or yi1 <= yi0:\n",
    "                    continue  # No valid overlap region\n",
    "\n",
    "                # STEP 6: Extract overlapping regions and compute intersection\n",
    "                mask_i = data_i['unique_mask'][yi0:yi1, xi0:xi1]\n",
    "                mask_j = data_j['unique_mask'][yj0:yj1, xj0:xj1]\n",
    "                \n",
    "                # Overlap mask: both trees cast shade at the same location\n",
    "                overlap_mask = mask_i & mask_j\n",
    "                overlap_area = overlap_mask.sum() * PIXEL_SIZE**2\n",
    "\n",
    "                if overlap_area > 0:\n",
    "                    overlap_records.append((site_i, site_j, overlap_area))\n",
    "\n",
    "                    # STEP 7: Calculate overlap shade on edges\n",
    "                    # Create transform for the overlap region (use patch i's coordinate system)\n",
    "                    overlap_window = Window(\n",
    "                        data_i['px'] - HALF_PATCH + xi0,\n",
    "                        data_i['py'] - HALF_PATCH + yi0,\n",
    "                        xi1 - xi0, yi1 - yi0\n",
    "                    )\n",
    "                    overlap_transform = rasterio.windows.transform(overlap_window, transform)\n",
    "                    \n",
    "                    # Compute edge intersections for overlap\n",
    "                    edge_intersections = compute_unique_shade_area(overlap_mask, overlap_transform, edges_gdf)\n",
    "                    for edge_id, length in edge_intersections:\n",
    "                        overlap_shade_on_edge_records.append((site_i, site_j, edge_id, length))\n",
    "\n",
    "        # Save results for this tile\n",
    "        if overlap_records:\n",
    "            df_overlap = pd.DataFrame(overlap_records, columns=[\"i\", \"j\", \"overlap_area\"])\n",
    "            df_overlap.to_csv(f\"data/final/overlap_tile/overlap_tile_{tile_id}.csv\", index=False)\n",
    "\n",
    "        if shade_on_edge_records:\n",
    "            df_shade_edge = pd.DataFrame(shade_on_edge_records, columns=[\"site_id\", \"edge_id\", \"shade_length\"])\n",
    "            df_shade_edge.to_csv(f\"data/final/shade_on_edge_tile/shade_on_edge_tile_{tile_id}.csv\", index=False)\n",
    "\n",
    "        if overlap_shade_on_edge_records:\n",
    "            df_overlap_shade_edge = pd.DataFrame(\n",
    "                overlap_shade_on_edge_records,\n",
    "                columns=[\"site_i\", \"site_j\", \"edge_id\", \"overlap_shade_length\"]\n",
    "            )\n",
    "            df_overlap_shade_edge.to_csv(\n",
    "                f\"data/final/overlap_shade_on_edge_tile/overlap_shade_on_edge_tile_{tile_id}.csv\",\n",
    "                index=False\n",
    "            )\n",
    "\n",
    "        # Save tile sites\n",
    "        tile_sites_out = sites_gdf.loc[tile_sites.index].copy()\n",
    "        tile_sites_out[\"original_index\"] = tile_sites_out.index\n",
    "        tile_sites_out.to_file(f\"data/final/sites_tile/sites_tile_{tile_id}.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "        print(f\"Saved tile {tile_id} data\")\n",
    "\n",
    "print(\"Processing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dcb195",
   "metadata": {},
   "source": [
    "Then, we can combine all the data by tiles into a single gdf or df, and store locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae570e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined 58\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Folder where individual overlap CSVs are saved\n",
    "overlap_folder = \"data/final/overlap_tile\"\n",
    "\n",
    "# Collect all filenames\n",
    "overlap_files = sorted([os.path.join(overlap_folder, f) \n",
    "                        for f in os.listdir(overlap_folder) \n",
    "                        if f.endswith(\".csv\")])\n",
    "\n",
    "# Read and concatenate\n",
    "overlap_dfs = []\n",
    "for f in overlap_files:\n",
    "    df = pd.read_csv(f)\n",
    "    overlap_dfs.append(df)\n",
    "\n",
    "# Combine all overlaps\n",
    "df_all_overlap = pd.concat(overlap_dfs, ignore_index=True)\n",
    "\n",
    "# Save the merged overlap file\n",
    "df_all_overlap.to_csv(\"data/final/tree_pairwise_overlap.csv\", index=False)\n",
    "\n",
    "print(f\"Combined {len(overlap_files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a25e9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined 58\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Folder where individual overlap CSVs are saved\n",
    "overlap_folder = \"data/final/shade_on_edge_tile\"\n",
    "\n",
    "# Collect all filenames\n",
    "overlap_files = sorted([os.path.join(overlap_folder, f) \n",
    "                        for f in os.listdir(overlap_folder) \n",
    "                        if f.endswith(\".csv\")])\n",
    "\n",
    "# Read and concatenate\n",
    "overlap_dfs = []\n",
    "for f in overlap_files:\n",
    "    df = pd.read_csv(f)\n",
    "    overlap_dfs.append(df)\n",
    "\n",
    "# Combine all overlaps\n",
    "df_all_overlap = pd.concat(overlap_dfs, ignore_index=True)\n",
    "\n",
    "# Save the merged overlap file\n",
    "df_all_overlap.to_csv(\"data/final/shade_on_edge.csv\", index=False)\n",
    "\n",
    "print(f\"Combined {len(overlap_files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "623abd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined 56\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Folder where individual overlap CSVs are saved\n",
    "overlap_folder = \"data/final/overlap_shade_on_edge_tile\"\n",
    "\n",
    "# Collect all filenames\n",
    "overlap_files = sorted([os.path.join(overlap_folder, f) \n",
    "                        for f in os.listdir(overlap_folder) \n",
    "                        if f.endswith(\".csv\")])\n",
    "\n",
    "# Read and concatenate\n",
    "overlap_dfs = []\n",
    "for f in overlap_files:\n",
    "    df = pd.read_csv(f)\n",
    "    overlap_dfs.append(df)\n",
    "\n",
    "# Combine all overlaps\n",
    "df_all_overlap = pd.concat(overlap_dfs, ignore_index=True)\n",
    "\n",
    "# Save the merged overlap file\n",
    "df_all_overlap.to_csv(\"data/final/overlap_shade_on_edge.csv\", index=False)\n",
    "\n",
    "print(f\"Combined {len(overlap_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1f8a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Folder where individual site GeoJSONs are saved\n",
    "sites_folder = \"data/final/sites_tile\"\n",
    "\n",
    "# Collect all filenames\n",
    "sites_files = sorted([os.path.join(sites_folder, f) \n",
    "                      for f in os.listdir(sites_folder) \n",
    "                      if f.endswith(\".geojson\")])\n",
    "\n",
    "# Read and concatenate\n",
    "sites_dfs = []\n",
    "for f in sites_files:\n",
    "    gdf = gpd.read_file(f)\n",
    "    sites_dfs.append(gdf)\n",
    "\n",
    "# Combine all sites_gdf\n",
    "gdf_all_sites = gpd.GeoDataFrame(pd.concat(sites_dfs, ignore_index=False))  # KEEP original index\n",
    "\n",
    "# Save the merged sites_gdf\n",
    "gdf_all_sites.to_file(\"data/final/tree_sites_all.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "print(f\"Combined {len(sites_files)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
