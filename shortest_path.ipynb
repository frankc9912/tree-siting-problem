{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f380a31",
   "metadata": {},
   "source": [
    "## OD Pairs\n",
    "\n",
    "In this notebook, we will use the ADVAN foot traffic data of July, 2024 (67,000+ records) to create a set of origin-destination (OD) pairs. Here are the steps:\n",
    "\n",
    "- Create Graph for pedestrian network using data from [DVRPC](https://www.arcgis.com/home/item.html?id=5959ca82848f4833a65cd90ef991c080)\n",
    "- Load the ADVAN foot traffic data to the nodes in the Graph\n",
    "- Create OD pairs by running `networkx.single_source_dijkstra_path_length()` on the Graph, and set the \"cutoff\" parameter to 2640 feet (0.5 miles)\n",
    "- Compute the weight of each OD pair using the formula, for each OD pair $(i,j)$:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "w_{ij} = \\text{visits}_i \\times \\frac{\\text{visits}_j}{\\sum_{\\text{reachable POIs for i}} \\text{visits}_j}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "- For each OD pair, we then compute the top 5 shortest paths using the `networkx.shortest_simple_paths()` function, we will use these paths to select the best path after graph update. Because people may not want to choose a fully-shaded long route, so we keep them to choose in a reasonable choice pool. This also saves computer resources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2f921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "from shapely.geometry import Point\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the pedestrian sidewalk network\n",
    "CRS = \"EPSG:6565\"\n",
    "sidewalk_edges = gpd.read_file(\"../data/sites/test/DVRPC_Pedestrian_Network.geojson\").to_crs(CRS)\n",
    "\n",
    "# Compute length of each LineString in feet (CRS 6565 is in feet)\n",
    "sidewalk_edges['length_ft'] = sidewalk_edges.geometry.length\n",
    "\n",
    "columns_to_keep = [\n",
    "    'objectid',         # Unique sidewalk ID\n",
    "    'geometry',         # LineString geometry\n",
    "    'length_ft',        # Length in feet\n",
    "]\n",
    "\n",
    "sidewalk_edges = sidewalk_edges[columns_to_keep]\n",
    "\n",
    "# Unique node ID mapping\n",
    "node_id_counter = 0\n",
    "node_id_map = {}\n",
    "\n",
    "def make_node_id(point, precision=3):\n",
    "    key = (round(point.x, precision), round(point.y, precision))\n",
    "    if key not in node_id_map:\n",
    "        global node_id_counter\n",
    "        node_id_map[key] = node_id_counter\n",
    "        node_id_counter += 1\n",
    "    return node_id_map[key]\n",
    "\n",
    "# Initialize graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add edges with progress bar and unique edge IDs\n",
    "edge_id_counter = 0\n",
    "\n",
    "for idx, row in tqdm(sidewalk_edges.iterrows(), total=sidewalk_edges.shape[0], desc=\"Building Graph\"):\n",
    "    geom = row.geometry\n",
    "    if geom is None or geom.is_empty or geom.geom_type != \"LineString\":\n",
    "        continue\n",
    "\n",
    "    start_point = Point(geom.coords[0])\n",
    "    end_point = Point(geom.coords[-1])\n",
    "\n",
    "    u = make_node_id(start_point)\n",
    "    v = make_node_id(end_point)\n",
    "\n",
    "    G.add_edge(\n",
    "        u, v,\n",
    "        geometry=geom,\n",
    "        length=row['length_ft'],\n",
    "        objectid=row['objectid'],\n",
    "        edge_id=edge_id_counter\n",
    "    )\n",
    "    edge_id_counter += 1\n",
    "\n",
    "# Attach coordinates to each node\n",
    "for (coord, node_id) in node_id_map.items():\n",
    "    G.nodes[node_id]['x'] = coord[0]\n",
    "    G.nodes[node_id]['y'] = coord[1]\n",
    "\n",
    "print(f\"Graph has {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# foot_traffic = gpd.read_file(\"../data/foot_traffic/advan_sg.geojson\").to_crs(CRS)\n",
    "foot_traffic = pd.read_csv(\"../data/foot_traffic/df_philly_24.csv\")\n",
    "foot_traffic = gpd.GeoDataFrame(\n",
    "    foot_traffic.loc[foot_traffic['RAW_VISIT_COUNTS'].notnull(), ['LATITUDE', 'LONGITUDE', 'RAW_VISIT_COUNTS']],\n",
    "    geometry=gpd.points_from_xy(\n",
    "        foot_traffic.loc[foot_traffic['RAW_VISIT_COUNTS'].notnull(), 'LONGITUDE'],\n",
    "        foot_traffic.loc[foot_traffic['RAW_VISIT_COUNTS'].notnull(), 'LATITUDE']\n",
    "    ),\n",
    "    crs=\"EPSG:4326\"\n",
    ").to_crs(CRS)\n",
    "foot_traffic = foot_traffic[[\"geometry\", \"RAW_VISIT_COUNTS\"]]\n",
    "\n",
    "# KDTree using node coordinates\n",
    "node_coords = np.array([[data['x'], data['y']] for node, data in G.nodes(data=True)])\n",
    "node_ids = [node for node in G.nodes]\n",
    "\n",
    "kdtree = cKDTree(node_coords)\n",
    "\n",
    "# Initialize node visit counts\n",
    "for node in G.nodes:\n",
    "    G.nodes[node]['visit_count'] = 0\n",
    "\n",
    "# Map POIs to nearest graph nodes\n",
    "for idx, row in tqdm(foot_traffic.iterrows(), total=foot_traffic.shape[0], desc=\"Mapping POIs\"):\n",
    "    poi_point = row.geometry\n",
    "    visits = row.RAW_VISIT_COUNTS\n",
    "\n",
    "    dist, node_idx = kdtree.query([poi_point.x, poi_point.y])\n",
    "    nearest_node = node_ids[node_idx]\n",
    "    G.nodes[nearest_node]['visit_count'] += visits\n",
    "\n",
    "print(\"POIs successfully mapped to graph nodes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba4e5e8",
   "metadata": {},
   "source": [
    "Here we get the OD pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4be3f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import nx_cugraph as nxcg\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 1. Load the OD-pair DataFrame from Parquet\n",
    "# ---------------------------------------------\n",
    "OD_pairs_df = pd.read_parquet(\"/mnt/e/Capstone/data/sites/test/OD_pairs.parquet\")\n",
    "OD_pairs = OD_pairs_df.to_dict(orient=\"records\")\n",
    "print(f\"Loaded {len(OD_pairs)} OD pairs from file.\")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 2. Load and Prepare the NetworkX Graph (G_ideal)\n",
    "# ------------------------------------------------\n",
    "with open(\"/mnt/e/Capstone/data/sites/test/G_ideal.pkl\", \"rb\") as f:\n",
    "    G_ideal = pickle.load(f)\n",
    "\n",
    "# Add a single numeric weight attribute 'lambda_e' (required by Dijkstra)\n",
    "for u, v, data in G_ideal.edges(data=True):\n",
    "    data[\"lambda_e\"] = data[\"length\"]\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 3. Convert the NetworkX graph to an nx_cugraph-backed graph\n",
    "# ----------------------------------------------------------\n",
    "# This conversion happens once; after this, any NetworkX call\n",
    "# on `nxcg_G` that is supported will dispatch to cuGraph.\n",
    "nxcg_G = nxcg.from_networkx(G_ideal)  # :contentReference[oaicite:2]{index=2}\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 4. Build a lookup that groups destinations by each origin\n",
    "# --------------------------------------------------------\n",
    "od_lookup = defaultdict(list)\n",
    "for od in OD_pairs:\n",
    "    origin = od[\"origin_node\"]\n",
    "    dest   = od[\"dest_node\"]\n",
    "    od_lookup[origin].append(dest)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. For each origin, run a single‐source Dijkstra on the GPU—\n",
    "#    collecting lengths for just those destinations of interest\n",
    "# ------------------------------------------------------------\n",
    "OD_results_ideal = []\n",
    "\n",
    "# tqdm to show progress; the call inside will automatically\n",
    "for origin_node in tqdm(od_lookup.keys(), desc=\"Computing ideal shortest paths\"):\n",
    "    # weight='lambda_e' tells Dijkstra to use the numeric attribute we set.\n",
    "    lengths = nx.single_source_dijkstra_path_length(\n",
    "        G_ideal, source=origin_node, weight=\"lambda_e\", cutoff=2640\n",
    "    )\n",
    "\n",
    "    # Extract only the distances to the specific destination nodes we care about\n",
    "    for dest_node in od_lookup[origin_node]:\n",
    "        path_length = lengths.get(dest_node, np.inf)\n",
    "        OD_results_ideal.append({\n",
    "            \"origin_node\": origin_node,\n",
    "            \"dest_node\":   dest_node,\n",
    "            \"path_length\": path_length\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028cf7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# 6. Save the results (e.g. back to a Parquet for lookup)\n",
    "# ----------------------------------------------------\n",
    "results_df = pd.DataFrame(OD_results_ideal)\n",
    "results_df.to_parquet(\"/mnt/e/Capstone/data/sites/test/OD_results_ideal.parquet\", index=False)\n",
    "\n",
    "print(\"Finished computing and storing all OD shortest-path lengths.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e089181e",
   "metadata": {},
   "source": [
    "Here we compute the weight for each OD pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ac4dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1) Load graph and set up edge weights\n",
    "with open(\"data/foot_traffic/G.pkl\", \"rb\") as f:\n",
    "    G_ideal = pickle.load(f)\n",
    "for u, v, data in G_ideal.edges(data=True):\n",
    "    data[\"lambda_e\"] = data[\"length\"]\n",
    "\n",
    "# 2) Build node DataFrame\n",
    "nodes = [{\"node\": n, **attrs} for n, attrs in G_ideal.nodes(data=True)]\n",
    "nodes_df = pd.DataFrame(nodes)\n",
    "\n",
    "# 3) Define both origin and destination sets as those with visit_count > 0\n",
    "high_visit = set(\n",
    "    nodes_df.loc[nodes_df[\"visit_count\"] > 0, \"node\"].tolist()\n",
    ")\n",
    "\n",
    "records = []\n",
    "for origin in tqdm(high_visit, desc=\"Computing ideal shortest paths\"):\n",
    "    # run Dijkstra from each high-visit origin\n",
    "    lengths = nx.single_source_dijkstra_path_length(\n",
    "        G_ideal,\n",
    "        source=origin,\n",
    "        weight=\"lambda_e\",\n",
    "        cutoff=2640\n",
    "    )\n",
    "    lengths.pop(origin, None)  # drop self\n",
    "\n",
    "    for dest, dist in lengths.items():\n",
    "        # only keep if dest also has visit_count>0, and enforce origin<dest\n",
    "        if dest in high_visit and origin < dest:\n",
    "            records.append({\n",
    "                \"origin_node\": origin,\n",
    "                \"dest_node\":   dest,\n",
    "                \"path_length\": dist\n",
    "            })\n",
    "\n",
    "# 4) Save\n",
    "od_df = pd.DataFrame.from_records(records)\n",
    "od_df.to_csv(\"data/foot_traffic/od_results_ideal.csv\", index=False)\n",
    "\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "# --- 1) Load the graph and extract visit_count per node ---\n",
    "with open(\"data/foot_traffic/G.pkl\", \"rb\") as f:\n",
    "    G_ideal = pickle.load(f)\n",
    "\n",
    "# Build a DataFrame mapping node -> visit_count\n",
    "nodes = [{\"node\": n, **data} for n, data in G_ideal.nodes(data=True)]\n",
    "nodes_df = pd.DataFrame(nodes)\n",
    "# make sure we have a column named 'visit_count' in nodes_df\n",
    "\n",
    "# --- 2) Load your precomputed OD pairs + baseline distances ---\n",
    "od_df = pd.read_csv(\"data/foot_traffic/od_results_ideal.csv\")\n",
    "# od_df has columns: origin_node, dest_node, path_length\n",
    "\n",
    "# --- 3) For each origin, compute sum of dest traffic ---\n",
    "# First, merge the dest visit_count into od_df\n",
    "od_df = od_df.merge(\n",
    "    nodes_df[[\"node\", \"visit_count\"]].rename(columns={\"node\":\"dest_node\",\"visit_count\":\"traffic_d\"}),\n",
    "    on=\"dest_node\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "od_df = od_df.merge(\n",
    "    nodes_df[[\"node\", \"visit_count\"]].rename(columns={\"node\":\"origin_node\",\"visit_count\":\"traffic_o\"}),\n",
    "    on=\"origin_node\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "\n",
    "# Then compute, per origin, the total traffic of all its destinations\n",
    "sum_traffic = od_df.groupby(\"origin_node\")[\"traffic_d\"].transform(\"sum\")\n",
    "\n",
    "# --- 4) Compute W(o,d) = traffic_d / sum_traffic_for_that_origin ---\n",
    "od_df[\"W\"] = od_df[\"traffic_d\"] / sum_traffic\n",
    "\n",
    "# --- 5) (Optional) Save W as a numpy array aligned with od_df order ---\n",
    "# W = od_df[\"W\"].values\n",
    "# np.save(\"data/foot_traffic/W.npy\", W)\n",
    "\n",
    "# If you want, also write back the full table with W:\n",
    "od_df.to_csv(\"data/foot_traffic/od_results_with_W.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9ae849",
   "metadata": {},
   "source": [
    "Here we calculate the top 5 shortest paths for each OD pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3ba905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building OD → top-5 edge paths: 100%|██████████| 1162489/1162489 [8:27:35<00:00, 38.17it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 shortest paths for all OD pairs saved!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1) Load the road graph\n",
    "with open(\"data/foot_traffic/G.pkl\", \"rb\") as f:\n",
    "    G = pickle.load(f)\n",
    "\n",
    "# 2) Load the baseline OD pairs\n",
    "od_df = pd.read_csv(\"data/foot_traffic/od_results_ideal.csv\")\n",
    "od_pairs = list(zip(od_df[\"origin_node\"], od_df[\"dest_node\"]))\n",
    "\n",
    "def get_edge_ids_from_node_path(G, node_path):\n",
    "    edge_ids = []\n",
    "    for u, v in zip(node_path, node_path[1:]):\n",
    "        data = G[u][v]\n",
    "        eid = data[\"edge_id\"]\n",
    "        edge_ids.append(int(eid))\n",
    "    return edge_ids\n",
    "\n",
    "# 3) For each OD pair, compute the 5 shortest edge-id paths\n",
    "od_top5_paths = []\n",
    "\n",
    "for origin, dest in tqdm(od_pairs, desc=\"Building OD → top-5 edge paths\"):\n",
    "    try:\n",
    "        all_paths_gen = nx.shortest_simple_paths(G, origin, dest, weight=\"length\")\n",
    "        top5 = []\n",
    "        for path_num, node_path in enumerate(all_paths_gen):\n",
    "            if path_num >= 5:\n",
    "                break\n",
    "            edge_ids = get_edge_ids_from_node_path(G, node_path)\n",
    "            top5.append(edge_ids)\n",
    "        # If less than 5 paths, pad with empty list\n",
    "        while len(top5) < 5:\n",
    "            top5.append([])\n",
    "        od_top5_paths.append({\n",
    "            \"origin_node\": int(origin),\n",
    "            \"dest_node\": int(dest),\n",
    "            \"top_1_shortest\": top5[0],\n",
    "            \"top_2_shortest\": top5[1],\n",
    "            \"top_3_shortest\": top5[2],\n",
    "            \"top_4_shortest\": top5[3],\n",
    "            \"top_5_shortest\": top5[4],\n",
    "        })\n",
    "    except nx.NetworkXNoPath:\n",
    "        continue\n",
    "\n",
    "# 4) Save as Pickle\n",
    "od_top5_df = pd.DataFrame(od_top5_paths)\n",
    "od_top5_df.to_pickle(\"data/foot_traffic/od_top5_shortest_paths.pkl\")\n",
    "\n",
    "print(\"Top-5 shortest paths for all OD pairs saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
